{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc82d969",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bc181c1",
   "metadata": {},
   "source": [
    "This case is about a bank (Thera Bank)\n",
    "\n",
    "Majority of these customers are liability customers (depositors) with varying size of deposits.\n",
    "\n",
    "The number of customers who are also borrowers (asset customers) is quite small, and the bank is interested in expanding \n",
    "this base rapidly to bring in more loan business and in the process, earn more through the interest on loans.\n",
    "\n",
    "In particular, the management wants to explore ways of converting its liability customers to personal loan customers \n",
    "(while retaining them as depositors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a98508",
   "metadata": {},
   "source": [
    "# DATA DISCRIPTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "337c42e8",
   "metadata": {},
   "source": [
    "1. ID: Customer ID\n",
    "2. Age: Customer's age in completed years\n",
    "3. Experience: #years of professional experience\n",
    "4. Income: Annual income of the customer ($000)\n",
    "5. ZIPCode: Home Address ZIP code.\n",
    "6. Family: Family size of the customer\n",
    "7. CCAvg: Avg. spending on credit cards per month ($000) \n",
    "8. Education: Education Level. 1: Undergrad; 2: Graduate; 3: Advanced/Professional\n",
    "9. Mortgage: Value of house mortgage if any.($000) \n",
    "10.Personal Loan: Did this customer accept the personal loan offered in the last campaign? \n",
    "11.Securities Account: Does the customer have a securities account with the bank?\n",
    "12.CD Account: Does the customer have a certificate of deposit (CD) account with the bank?\n",
    "13.Online: Does the customer use internet banking facilities? \n",
    "14.CreditCard: Does the customer uses a credit card issued by UniversalBank?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4063c9",
   "metadata": {},
   "source": [
    "# Problem Objective"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b55313b7",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will build a model which will idetify the potential customers amongst the existing liability customers who has higher\n",
    "chances of taking the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9e57d",
   "metadata": {},
   "source": [
    "# Data Exploration and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99049191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1676c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source\n",
    "url = \"https://github.com/rahul-more14/Machine-Learning-Project/blob/main/Bank_Personal_Loan_Modelling.xlsx?raw=True\"\n",
    "\n",
    "# Importing Data\n",
    "data1=pd.read_excel(url, sheet_name=\"Data\")\n",
    "\n",
    "# Printing Data\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385df8b7",
   "metadata": {},
   "source": [
    "# NOTE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bf1c5c6",
   "metadata": {},
   "source": [
    "Personal Loan is the Target Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting General Infomation of the Data\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3be8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and Columns\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab92d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns Values\n",
    "data1.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39924d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable format\n",
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cd3a7",
   "metadata": {},
   "source": [
    "# Observations:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "987a9126",
   "metadata": {},
   "source": [
    "1. Data has 13 Variables and 5000 observations.\n",
    "\n",
    "2. There is no null value.\n",
    "\n",
    "3. There is only one variable with Folat values and the rest are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing first 10 observations\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdc643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idetifying any unique Identifier\n",
    "data1.columns.values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89a0414f",
   "metadata": {},
   "source": [
    " Here ID is the unique Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the categorical and discrete variables?\n",
    "print(data1.dtypes)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "546816c7",
   "metadata": {},
   "source": [
    "Categorical Variables:\n",
    "\n",
    "1.ZIP Code\n",
    "2.Family\n",
    "3.Education\n",
    "4.Personal Loan\n",
    "5.Securities Account\n",
    "6.CD Account\n",
    "7.Online\n",
    "8.CreditCard\n",
    "\n",
    "Continuous Variables:\n",
    "\n",
    "1.Age\n",
    "2.Experience\n",
    "3.Income\n",
    "4.CCAvg\n",
    "5.Mortgage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f004c4",
   "metadata": {},
   "source": [
    "# Categorical Variable Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d042d9c",
   "metadata": {},
   "source": [
    "# 1. Zip Code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38864898",
   "metadata": {},
   "source": [
    "NOTE: This Variable is not useful in buildinf the model. and hence variable exploration is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f71674",
   "metadata": {},
   "source": [
    "# 2. Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bf60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the family variable.\n",
    "print(data1['Family'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"Family\" , data=data1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94a8b3b6",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. The variable Family is the number of dependent members in the customers Family.\n",
    "2. This variable takes values 1,2,3 and 4.\n",
    "3. No outlier detection.\n",
    "4. No null value\n",
    "5. customer with only one Family member is maximum.\n",
    "6. The variable is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6606648",
   "metadata": {},
   "source": [
    "# 3. Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7578108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the Education variable.\n",
    "print(data1['Education'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"Education\" , data=data1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "917755a0",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. Education take values of 1,2 or 3.\n",
    "2. 1 for under Graduate, 2 for Graduate and 3 for Post Graduate.\n",
    "3. All the values in the data takes one of these three possible value.\n",
    "4. No outlier detection.\n",
    "5. No Null Value.\n",
    "6. Customers who are under graduate is more in number.\n",
    "7. This Variable is clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1a7b9",
   "metadata": {},
   "source": [
    "# 4. Personal Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e13b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the Personal Loan variable.\n",
    "print(data1['Personal Loan'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"Personal Loan\" , data=data1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "026cbfea",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. This Variable personal loan take two values 0 and 1\n",
    "2. 0 indicating that customer did not accept the personal loan offered in the last campaign and 1 indicates that the \n",
    "    customer accepted the personal loan offered in the last campaign.\n",
    "3. There is no null value.\n",
    "4. No outlier detection.\n",
    "5. This variable is clean.\n",
    "6.The varible is highly imbalance. That is the class 0 values dominates over class 1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating a copy of the dataframe so that the original data is not lost\n",
    "data = data1 \n",
    "\n",
    "# NOTE: data1 is the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa785b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551157f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Personal Loan column\n",
    "data.rename(columns={\"Personal Loan\":\"Personal_Loan\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec77798",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d566b",
   "metadata": {},
   "source": [
    "# 5. Securities Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the Securities Account variable.\n",
    "print(data['Securities Account'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"Securities Account\" , data=data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d64c6c4a",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. This Variable Securities Account take two values 0 and 1\n",
    "2. 0 indicating that customer do not have Securities Account with bank and 1 indicates that \n",
    "    customer has Securities Account with bank.\n",
    "3. There is no null value.\n",
    "4. No outlier detection.\n",
    "5. This variable is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2887e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Personal Loan column\n",
    "data.rename(columns={\"Securities Account\":\"Securities_Account\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2d0d2",
   "metadata": {},
   "source": [
    "# 6. CD Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4aac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the CD Accountt variable.\n",
    "print(data['CD Account'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"CD Account\" , data=data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce6a4f12",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. This Variable CD Account take two values 0 and 1\n",
    "2. 0 indicating that customer do not have Certificate of deposite(CD) with bank and 1 indicates that \n",
    "    customer has Certificate of deposite(CD) account with bank.\n",
    "3. There is no null value.\n",
    "4. No outlier detection.\n",
    "5. This variable is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming CD account column\n",
    "data.rename(columns={\"CD Account\":\"CD_Account\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eacc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52285f1",
   "metadata": {},
   "source": [
    "# 7. Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the Online variable.\n",
    "print(data['Online'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"Online\" , data=data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d45966",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. This Variable Online take two values 0 and 1\n",
    "2. 0 indicating that customer do not use internet banking facility and 1 indicates that \n",
    "    customer uses the internet banking facility. \n",
    "3. There is no null value.\n",
    "4. No outlier detection.\n",
    "5. This variable is clean.\n",
    "6. A large number of customers uses internet banking facility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004e30c",
   "metadata": {},
   "source": [
    "# 8. CreditCard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the value's in the CreditCard variable.\n",
    "print(data['CreditCard'].value_counts())\n",
    "\n",
    "# Plotting the count plot\n",
    "sns.countplot(y=\"CreditCard\" , data=data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9607056f",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. This Variable Online take two values 0 and 1\n",
    "2. 0 indicating that customer do not use Credit card issued by Universal bank and 1 indicates that \n",
    "    customer uses Credit card issued by universal bank. \n",
    "3. There is no null value.\n",
    "4. No outlier detection.\n",
    "5. This variable is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f41da2",
   "metadata": {},
   "source": [
    "# Continuous Variable Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699cea39",
   "metadata": {},
   "source": [
    "# 1. CCAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot\n",
    "plt.boxplot(data[\"CCAvg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "plt.hist(data[\"CCAvg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentiles = data[\"CCAvg\"].quantile([0.01,0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.60,0.65,0.70,0.75,\n",
    "                                      0.80,0.90,0.91,0.92,0.93,0.932,0.935,0.94,0.95,0.96,0.96,0.97,0.98,0.99,0.995,0.999,1])\n",
    "\n",
    "Percentiles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ace7921",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. CCAvg (Average credit card spending in 000\\$) lies in the range 0$ to 10000\\$.\n",
    "2. From boxplot it is clear there is presence of outlier in ccAvg variable.\n",
    "3. This variable needs cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c765d",
   "metadata": {},
   "source": [
    "# 2. Mortgage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5168b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot\n",
    "plt.boxplot(data[\"Mortgage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4069282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "plt.hist(data[\"Mortgage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5276aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentiles = data[\"Mortgage\"].quantile([0.01,0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.60,0.65,0.70,0.75,\n",
    "                                      0.80,0.90,0.91,0.92,0.93,0.932,0.935,0.94,0.95,0.96,0.96,0.97,0.98,0.99,0.995,0.999,1])\n",
    "\n",
    "Percentiles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9b1790b",
   "metadata": {},
   "source": [
    "Onservations:\n",
    "1. From the boxplot it can be observed that there is presence of outliers.\n",
    "2. 65% of the data takes 0 value and the rest of the 45% takes comparatively very large values.\n",
    "3. In this variable imputation is not a good choice for cleaning.\n",
    "4. So we will create a new flag variable with 0 indicating that the customer have not taken any house mortgage \n",
    "    and 1 if the customer has taken a house mortgage. we will drop the original variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291a595",
   "metadata": {},
   "source": [
    "# 3. Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7310a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot\n",
    "plt.boxplot(data[\"Income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8619725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "plt.hist(data[\"Income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentiles = data[\"Income\"].quantile([0.01,0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.60,0.65,0.70,0.75,\n",
    "                                      0.80,0.90,0.91,0.92,0.93,0.932,0.935,0.94,0.95,0.96,0.96,0.97,0.98,0.99,0.995,0.999,1])\n",
    "\n",
    "Percentiles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5398ee5b",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. From the boxplot it is clear that there is outliers.\n",
    "2. This variable needs cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4e516",
   "metadata": {},
   "source": [
    "# 4. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot\n",
    "plt.boxplot(data[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "plt.hist(data[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c466a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentiles = data[\"Age\"].quantile([0.01,0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.60,0.65,0.70,0.75,\n",
    "                                      0.80,0.90,0.91,0.92,0.93,0.932,0.935,0.94,0.95,0.96,0.96,0.97,0.98,0.99,0.995,0.999,1])\n",
    "\n",
    "Percentiles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00de7172",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. All the bank customers will be of age equal to or above 18.\n",
    "2. Minimum value of age to get a personal loan is 18.\n",
    "3. Hence, Age variable lies in the range[18 , 100] with 100 being the extreme case.\n",
    "4. all the values lies within the range.\n",
    "5. There is no outlier detection.\n",
    "6. This variable is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a150d",
   "metadata": {},
   "source": [
    "# 5. Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot\n",
    "plt.boxplot(data[\"Experience\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "plt.hist(data[\"Experience\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f06336",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentiles = data[\"Experience\"].quantile([0.01,0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.60,0.65,0.70,0.75,\n",
    "                                      0.80,0.90,0.91,0.92,0.93,0.932,0.935,0.94,0.95,0.96,0.96,0.97,0.98,0.99,0.995,0.999,1])\n",
    "\n",
    "Percentiles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6174c00b",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. This variable experience is in years and it can only takes positive integers.\n",
    "2. But the data has some negative values.\n",
    "3. These values needs to be cleaned.\n",
    "4. The range for the Experience value is [0,60]\n",
    "5. we are taking the max range value as 60 because 60 is the retirenment age.\n",
    "6. There are some negative values in the data and There values needs to be cleaned.\n",
    "7. No null value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39858a",
   "metadata": {},
   "source": [
    "# Data Cleaning and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b7043",
   "metadata": {},
   "source": [
    "# Categorical variable cleaning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f5c0ed6",
   "metadata": {},
   "source": [
    "All the categorical variable are clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c11730",
   "metadata": {},
   "source": [
    "# Continuous Variable Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b2c6c",
   "metadata": {},
   "source": [
    "# 1.Experience Variable"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17f9878d",
   "metadata": {},
   "source": [
    "Experience Variable has negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of entries with negative value\n",
    "mask=data[\"Experience\"]<0\n",
    "data[\"Experience\"][mask].count()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff80e84c",
   "metadata": {},
   "source": [
    "There are 53 records with negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ffa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average of the non negative entries.\n",
    "mask1=data[\"Experience\"]>0\n",
    "median=data[\"Experience\"][mask1].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the negative entries with median value.\n",
    "data[\"Experience_new\"]=data[\"Experience\"]\n",
    "data[\"Experience_new\"][mask]=median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6681c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the Experience_new variable for negative value's\n",
    "\n",
    "data[\"Experience_new\"][data[\"Experience_new\"]<0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc77b98",
   "metadata": {},
   "source": [
    "# 2. CCAvg Variable"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4b6743c",
   "metadata": {},
   "source": [
    "Applying log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50715d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data[\"log_CCAvg\"] = np.log(data[\"CCAvg\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1216ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data[\"log_CCAvg\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e93e9cc8",
   "metadata": {},
   "source": [
    "We Can see that after applying log transformation there is no outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"log_CCAvg\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c165fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"log_CCAvg\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc0ccf",
   "metadata": {},
   "source": [
    "# 3. Mortgage variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35135345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating a new zero column for flag variable.\n",
    "data[\"Mortgage_flag\"]=0\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06891a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3=data[\"Mortgage\"]>0\n",
    "data[\"Mortgage_flag\"][mask3] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429cc1f",
   "metadata": {},
   "source": [
    "# 4. Income Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2974906",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sqrt_income\"]=np.sqrt(data[\"Income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data['sqrt_income'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd36bd7e",
   "metadata": {},
   "source": [
    "We can see after applying square root transformation there is no outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c22039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sqrt_income\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sqrt_income\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195fffb",
   "metadata": {},
   "source": [
    "# Removal of columns that are not used in model building"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca4fc1a2",
   "metadata": {},
   "source": [
    "Since we made new columns for the cleaned data, we will create a new data frame with only the cleaned columns \n",
    "that we will later use to build the model.\n",
    "\n",
    "We will remove the ID and ZIP code variable as it is clear from the business background that the ID doesn't contribute in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.drop(['CCAvg', 'Mortgage', 'Experience', 'Income', 'ID', 'ZIP Code'], axis = 1)\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20436d",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d354a",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8c2874e",
   "metadata": {},
   "source": [
    "Since the target variable takes values of 0 and 1 hence logistic regression model is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edf314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  x contains all other variable except target variable(Personal Loan)\n",
    "X = data_new.drop([\"Personal_Loan\"], axis = 1)\n",
    "#  y contains Target variable(Personal Loan)\n",
    "y = data_new[\"Personal_Loan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef71618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4007947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking intercept and coefficient values.\n",
    "print(\"Intercept =\" , logistic.intercept_)\n",
    "print(\"coefficient = \\n \" , logistic.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da317666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the accuracy of the model on train data\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predict = logistic.predict(X)\n",
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy on train data for all the variables =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e84354",
   "metadata": {},
   "source": [
    "# checking the p value of the variables to find the impactful and non impactful variables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e07e16f7",
   "metadata": {},
   "source": [
    "A variable is impactful when p value <0.05 and non impactful when p value is >0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  checking the p value for individual impact of the variables on the traget variable.\n",
    "import statsmodels.api as sm\n",
    "sm = sm.Logit(y,X)\n",
    "sm.fit()\n",
    "print(sm.fit().summary())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f3ee5fd",
   "metadata": {},
   "source": [
    "We can see that p value of family and Mortagage variable is Greater than 0.05 which indicates that the variable not impactful.\n",
    "\n",
    "However before removing these variables we will first check the VIF(variable inflation factor) for multicollinearity between variable, as if there is any multicollinearity between variables it will have impact on the p value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16203d39",
   "metadata": {},
   "source": [
    "# VIF"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df8f700f",
   "metadata": {},
   "source": [
    "If VIF >5 for any two or more variables, then it is a clear case of multicollinearity between those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user defined function for variation Inflation factor\n",
    "# def vif_cal(input_data,dependent_col):\n",
    "#     import statsmodels.formula.api as sm\n",
    "#     x_vars=input_data.drop([dependent_col], axis=1)\n",
    "#     xvar_names=x_vars.columns\n",
    "#     for i in range(0, xvar_names.shape[0]):\n",
    "#         y=x_vars[xvar_names[i]]\n",
    "#         x=x_vars[xvar_names.drop(xvar_names[i])]\n",
    "#         rsq=sm.ols(formula=\"y-x\", data=x_vars).fit().rsquared\n",
    "#         vif=round(1/(1-rsq),2)\n",
    "#         print (xvar_names[i], \"VIF = \" , vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25370f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_cal(input_data, dependent_col):\n",
    "    import statsmodels.formula.api as sm\n",
    "    x_vars = input_data.drop([dependent_col], axis=1)\n",
    "    xvar_names = x_vars.columns\n",
    "    for i in range(0, xvar_names.shape[0]):\n",
    "        y = x_vars[xvar_names[i]]\n",
    "        x = x_vars[xvar_names.drop(xvar_names[i])]\n",
    "        rsq = sm.ols(formula=f\"{xvar_names[i]} ~ {' + '.join(xvar_names.drop(xvar_names[i]))}\", data=x_vars).fit().rsquared\n",
    "        vif = round(1 / (1 - rsq), 2)\n",
    "        print(xvar_names[i], \"VIF =\", vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f192dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF\n",
    "vif_cal(data_new,\"Personal_Loan\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae4244f3",
   "metadata": {},
   "source": [
    "We can See that VIF of age variable and Experience variable is >5 which shows a clear case of multicollinearity.\n",
    "\n",
    "we will first remove variable with highest VIF and rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_new.drop([\"Personal_Loan\", \"Age\"], axis = 1)\n",
    "y = data_new[\"Personal_Loan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e754f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking intercept and coefficient values.\n",
    "print(\"Intercept =\" , logistic.intercept_)\n",
    "print(\"coefficient = \\n \" , logistic.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the accuracy of the model on train data\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predict = logistic.predict(X)\n",
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy on train data for all the variables =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Rechecking the p value for individual impact of the variables on the traget variable.\n",
    "import statsmodels.api as sm\n",
    "sm = sm.Logit(y,X)\n",
    "sm.fit()\n",
    "print(sm.fit().summary())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1779e8cc",
   "metadata": {},
   "source": [
    "We can Observe that now the p value of all the variables is <0.05\n",
    "\n",
    "we will once again check multicolinearity of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF\n",
    "vif_cal(data_new.drop(['Age'] , axis=1), \"Personal_Loan\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ff8b8ca",
   "metadata": {},
   "source": [
    "Now we can see that the VIF of all the variables is <5. Hence there is not multicollinearity between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c200",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_new[\"Personal_Loan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Building a Decision Tree Model\n",
    "Dtree = DecisionTreeClassifier(max_depth = 2)\n",
    "Dtree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cda465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the tree\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "plt.figure(figsize = (15,7))\n",
    "plot_tree(Dtree, filled = True, rounded = True, impurity=False, feature_names=list(X.columns))\n",
    "print(export_text(Dtree , feature_names = list(X.columns)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the accuracy of the model\n",
    "predict = Dtree.predict(X)\n",
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy on train data for all the variables =\", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "761ab34b",
   "metadata": {},
   "source": [
    "The Problem Of overfitting\n",
    "\n",
    "When really large tree is build, the model is very likely to be Overfitted model means that the train accuracy is very large\n",
    "whereas the test accuracy is considerably very low. If the train and test accuracy diifer by more than 5 points then the model \n",
    "is considered as overfitted model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_new[\"Personal_Loan\"]\n",
    "\n",
    "# Creating train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4850385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "from sklearn import tree\n",
    "Dtree1=tree.DecisionTreeClassifier(max_depth = 1)\n",
    "Dtree1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a63261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the model using train data\n",
    "from sklearn.tree import plot_tree , export_text\n",
    "plt.figure(figsize = (15 ,7))\n",
    "plot_tree(Dtree1, filled = True, rounded =True, impurity = False, feature_names = list(X.columns))\n",
    "print(export_text(Dtree1, feature_names=list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10288a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the accuracy of the model on train data\n",
    "predict = Dtree.predict(X_train)\n",
    "cm = confusion_matrix(y_train, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy on train data for all the variables =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the accuracy of the model on test data\n",
    "predict = Dtree.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy on test data for all the variables =\", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96d8728e",
   "metadata": {},
   "source": [
    "Here we can observe that the train and test accuracy are close enough. Hence the model is not Overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c5222",
   "metadata": {},
   "source": [
    "# Model Selection And Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb2844",
   "metadata": {},
   "source": [
    "# Sensitivity And Specificity-Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_new[\"Personal_Loan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9988ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the if a person takes personal loan or not using logistic fit.\n",
    "prediction_probability = logistic.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab49a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probability[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e73299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for threshold = 0.5\n",
    "threshold = 0.5\n",
    "predict = [0 if x < threshold else 1 for x in list(prediction_probability[: , 1])]\n",
    "predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf070540",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy  =\", accuracy)\n",
    "\n",
    "sensitivity = (cm[0,0])/total\n",
    "print(\"Sensitivity = \" , sensitivity)\n",
    "\n",
    "specificity = (cm[1,1])/total\n",
    "print(\"specificity = \" , specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10187e34",
   "metadata": {},
   "source": [
    "# Threshold"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a29af11",
   "metadata": {},
   "source": [
    "Sensitivity and specificity with different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prediction for threshold\n",
    "threshold1 = 0.2\n",
    "predict1 = [0 if x < threshold1 else 1 for x in list(prediction_probability[: , 1])]\n",
    "\n",
    "cm1 = confusion_matrix(y, predict1)\n",
    "print(\"Confusion matrix = \\n\" , cm1)\n",
    "\n",
    "total1 = sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1]) / total1\n",
    "print(\"Overall accuracy  =\", accuracy1)\n",
    "\n",
    "sensitivity1 = (cm1[0,0])/total1\n",
    "print(\"Sensitivity = \" , sensitivity1)\n",
    "\n",
    "specificity1= (cm1[1,1])/total1\n",
    "print(\"specificity = \" , specificity1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f34ca49e",
   "metadata": {},
   "source": [
    "As Threshold decreases from 0.5 to 0.2, the sensitivity decreases(class 0 accuracy) and the specificity increases(class 1 accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prediction for threshold\n",
    "threshold1 = 0.8\n",
    "predict1 = [0 if x < threshold1 else 1 for x in list(prediction_probability[: , 1])]\n",
    "\n",
    "cm1 = confusion_matrix(y, predict1)\n",
    "print(\"Confusion matrix = \\n\" , cm1)\n",
    "\n",
    "total1 = sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1]) / total1\n",
    "print(\"Overall accuracy  =\", accuracy1)\n",
    "\n",
    "sensitivity1 = (cm1[0,0])/total1\n",
    "print(\"Sensitivity = \" , sensitivity1)\n",
    "\n",
    "specificity1= (cm1[1,1])/total1\n",
    "print(\"specificity = \" , specificity1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e2cb9f5",
   "metadata": {},
   "source": [
    " As Threshold increases from 0.5 to 0.8, the sensitivity (class 0 accuracy)increases and the specificity(class 1 accuracy)decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920b8bf",
   "metadata": {},
   "source": [
    "# Precision, Recall and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating precision , recall and F1 Score\n",
    "threshold1 = 0.5\n",
    "predict1 = [0 if x < threshold1 else 1 for x in list(prediction_probability[: , 1])]\n",
    "\n",
    "cm1 = confusion_matrix(y, predict1)\n",
    "print(\"Confusion matrix = \\n\" , cm1)\n",
    "\n",
    "total1 = sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1]) / total1\n",
    "print(\"Overall accuracy  =\", accuracy1)\n",
    "\n",
    "Precision_class0 = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "print(\"precision of class 0 = \" , Precision_class0 )\n",
    "\n",
    "Precision_class1 = cm1[1,1]/(cm1[0,1]+cm1[1,1])\n",
    "print(\"precision of class 1 = \" , Precision_class1 )\n",
    "\n",
    "Recall_class0 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print(\"Recall of class 0 = \" , Recall_class0 )\n",
    "\n",
    "Recall_class1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print(\"Recall of class 1 = \" , Recall_class1 )\n",
    "\n",
    "F1_Class1 = 2/((1/Precision_class1)+(1/Recall_class1))\n",
    "print(\"F1 score of class 1 = \" ,F1_Class1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd2b80",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da494b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count of the target variable\n",
    "freq = data_new [\"Personal_Loan\"].value_counts()\n",
    "print(freq)\n",
    "print((freq / (freq.sum()))*100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06482360",
   "metadata": {},
   "source": [
    "We can observe that 90.4% of the personal loan takes value 0 and only 9% of the values are 1.\n",
    "\n",
    "This Clearly an imbalanced data.\n",
    "\n",
    "To balance this data we will do understanding of the class 0 and oversampling of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating balanced data\n",
    "mask1 = data_new[\"Personal_Loan\"]==0\n",
    "mask2 = data_new[\"Personal_Loan\"]==1\n",
    "\n",
    "PL_class0 = data_new[mask1]\n",
    "PL_class1 = data_new[mask2]\n",
    "PL_class0_US = PL_class0.sample(int(0.6*len(PL_class0))) # undersampling of class 0\n",
    "PL_class1_OS = PL_class1.sample(int(3*len(PL_class1)) , replace = True) # Oversampling of class 1\n",
    "\n",
    "data_balanced = pd.concat([PL_class0_US , PL_class1_OS])\n",
    "print(\"Final balanced data shape\" , data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count of the balanced data\n",
    "freq = data_balanced [\"Personal_Loan\"].value_counts()\n",
    "print(freq)\n",
    "print((freq / (freq.sum()))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa884861",
   "metadata": {},
   "source": [
    "# Logistic Regression On Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_balanced[\"Personal_Loan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066507b3",
   "metadata": {},
   "source": [
    "# Updated Sensitivity And Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the if a person takes personal loan or not using logistic fit\n",
    "prediction_probability = logistic.predict_proba(X)\n",
    "\n",
    "threshold = 0.5\n",
    "predict = [0 if x < threshold else 1 for x in list(prediction_probability[: , 1])]\n",
    "predict[0:10]\n",
    "\n",
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy  =\", accuracy)\n",
    "\n",
    "sensitivity = (cm[0,0])/total\n",
    "print(\"Sensitivity = \" , sensitivity)\n",
    "\n",
    "specificity = (cm[1,1])/total\n",
    "print(\"specificity = \" , specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77762372",
   "metadata": {},
   "source": [
    "# Updated precision, recall and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba47cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating precision , recall and F1 Score\n",
    "threshold1 = 0.5\n",
    "predict1 = [0 if x < threshold1 else 1 for x in list(prediction_probability[: , 1])]\n",
    "\n",
    "cm1 = confusion_matrix(y, predict1)\n",
    "print(\"Confusion matrix = \\n\" , cm1)\n",
    "\n",
    "total1 = sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1]) / total1\n",
    "print(\"Overall accuracy  =\", accuracy1)\n",
    "\n",
    "Precision_class0 = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "print(\"precision of class 0 = \" , Precision_class0 )\n",
    "\n",
    "Precision_class1 = cm1[1,1]/(cm1[0,1]+cm1[1,1])\n",
    "print(\"precision of class 1 = \" , Precision_class1 )\n",
    "\n",
    "Recall_class0 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print(\"Recall of class 0 = \" , Recall_class0 )\n",
    "\n",
    "Recall_class1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print(\"Recall of class 1 = \" , Recall_class1 )\n",
    "\n",
    "F1_Class1 = 2/((1/Precision_class1)+(1/Recall_class1))\n",
    "print(\"F1 score of class 1 = \" ,F1_Class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebb42b",
   "metadata": {},
   "source": [
    "# Decision tree on Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_balanced[\"Personal_Loan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84532829",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtree = DecisionTreeClassifier(max_depth = 2)\n",
    "Dtree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the tree\n",
    "from sklearn.tree import plot_tree , export_text\n",
    "plt.figure(figsize = (15 ,7))\n",
    "plot_tree(Dtree, filled = True, rounded =True, impurity = False, feature_names = list(X.columns))\n",
    "print(export_text(Dtree, feature_names=list(X.columns)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cef1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the accuracy of the model\n",
    "predict = Dtree.predict(X)\n",
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy on train data for all the variables =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495e50c",
   "metadata": {},
   "source": [
    "# Updated Sensitivity And Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a49781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the if a person takes personal loan or not using logistic fit\n",
    "prediction_probability = logistic.predict_proba(X)\n",
    "\n",
    "threshold = 0.5\n",
    "predict = [0 if x < threshold else 1 for x in list(prediction_probability[: , 1])]\n",
    "predict[0:10]\n",
    "\n",
    "cm = confusion_matrix(y, predict)\n",
    "print(\"Confusion matrix = \\n\" , cm)\n",
    "\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print(\"Overall accuracy  =\", accuracy)\n",
    "\n",
    "sensitivity = (cm[0,0])/total\n",
    "print(\"Sensitivity = \" , sensitivity)\n",
    "\n",
    "specificity = (cm[1,1])/total\n",
    "print(\"specificity = \" , specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931614a",
   "metadata": {},
   "source": [
    "# Updated Precision, Recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating precision , recall and F1 Score\n",
    "threshold1 = 0.5\n",
    "predict1 = [0 if x < threshold1 else 1 for x in list(prediction_probability[: , 1])]\n",
    "\n",
    "cm1 = confusion_matrix(y, predict1)\n",
    "print(\"Confusion matrix = \\n\" , cm1)\n",
    "\n",
    "total1 = sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1]) / total1\n",
    "print(\"Overall accuracy  =\", accuracy1)\n",
    "\n",
    "Precision_class0 = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "print(\"precision of class 0 = \" , Precision_class0 )\n",
    "\n",
    "Precision_class1 = cm1[1,1]/(cm1[0,1]+cm1[1,1])\n",
    "print(\"precision of class 1 = \" , Precision_class1 )\n",
    "\n",
    "Recall_class0 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print(\"Recall of class 0 = \" , Recall_class0 )\n",
    "\n",
    "Recall_class1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print(\"Recall of class 1 = \" , Recall_class1 )\n",
    "\n",
    "F1_Class1 = 2/((1/Precision_class1)+(1/Recall_class1))\n",
    "print(\"F1 score of class 1 = \" ,F1_Class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913413d",
   "metadata": {},
   "source": [
    "# K Fold Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_balanced[\"Personal_Loan\"]\n",
    "\n",
    "Dtree = DecisionTreeClassifier(max_depth = 2)\n",
    "\n",
    "# Simple K-Fold cross validation. 10 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kfold_models = KFold(n_splits=10)\n",
    "\n",
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(Dtree,X, y, cv = kfold_models)\n",
    "print(scores)\n",
    "print(\"Avg K-Fold Accuracy\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47b518",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_balanced[\"Personal_Loan\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, train_size=0.8)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc38874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(n_estimators=200, max_features=4, max_depth=6)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on train data\n",
    "Forest_predict_train=forest.predict(X_train)\n",
    "\n",
    "# Predicting on test data\n",
    "Forest_predict_test=forest.predict(X_test)\n",
    "\n",
    "# Train data validation\n",
    "cm1 = confusion_matrix(y_train, Forest_predict_train)\n",
    "print(\"Confusion matrix for train data = \\n\" , cm1)\n",
    "\n",
    "total1 = sum(sum(cm1))\n",
    "accuracy_tree = (cm1[0,0]+cm1[1,1]) / total1\n",
    "print(\"Accuracy of train data \\n\", accuracy_tree)\n",
    "\n",
    "# Testdata validation\n",
    "cm2 = confusion_matrix(y_test, Forest_predict_test)\n",
    "print(\"Confusion matrix for test data = \\n\" , cm2)\n",
    "\n",
    "total1 = sum(sum(cm2))\n",
    "accuracy_tree = (cm2[0,0]+cm2[1,1]) / total1\n",
    "print(\"Accuracy of test data \\n\", accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d9ea8",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5c22c",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model(GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.drop([\"Personal_Loan\"], axis=1)\n",
    "y=data_balanced[\"Personal_Loan\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5124a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "\n",
    "# Building the GBM\n",
    "boost=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, verbose=1)\n",
    "\n",
    "# fitting the gradient boost classifier\n",
    "start_time = time.time()\n",
    "boost.fit(X_train,y_train)\n",
    "print(\"Time taken by GBM \"+ str((time.time() - start_time))+ \" Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50837e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting Gradient boosting model on the train data\n",
    "boost_predict_train=boost.predict(X_train)\n",
    "cm1 = confusion_matrix(y_train, boost_predict_train)\n",
    "print(cm1)\n",
    "\n",
    "total = sum(sum(cm1))\n",
    "from sklearn.metrics import f1_score\n",
    "accuracy_train = f1_score(y_train, boost_predict_train, average='micro')\n",
    "print(\"train accuracy\", accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting gradient boosting model on the test data\n",
    "boost_predict_test=boost.predict(X_test)\n",
    "cm1 = confusion_matrix(y_test, boost_predict_test)\n",
    "print(cm1)\n",
    "\n",
    "accuracy_test = f1_score(y_test, boost_predict_test, average='micro')\n",
    "print(\"test accuracy\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ab828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
